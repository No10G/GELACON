import streamlit as st
import pandas as pd
import numpy as np
import joblib 
import json
import os
import plotly.express as px 
import sys 

# --- 0. ãƒ•ã‚¡ã‚¤ãƒ«ã¨å®šæ•°ã®è¨­å®š ---
MODEL_FILE = 'gelacon_predictor_model.pkl'
PAST_CACHE_FILE = 'past_data.json'
FUTURE_CACHE_FILE = 'CF_data.json' 
FEATURE_CACHE_FILE = 'XGBoost_Features_Cache.json'

# è£œæ­£å€¤ã¨ã‚³ãƒ¼ã‚¹å®šç¾©
COURSE_TARGETS = {
	'Kandatsu': [900, 700, 500],
	'Marunuma': [1950, 1700, 1500, 1300]
}
AMEDAS_ELEVATIONS = {'Kandatsu': 340, 'Marunuma': 370} 
CONDITIONS = {0: 'ãƒ‘ã‚¦ãƒ€ãƒ¼', 1: 'ç¥ãƒãƒ¼ãƒ³', 2: 'ã‚¢ã‚¤ã‚¹ãƒãƒ¼ãƒ³', 3: 'ã‚·ãƒ£ãƒé›ª/ã‚´ãƒ­ã‚´ãƒ­é›ª'}
CONDITION_EMOJIS = {'ãƒ‘ã‚¦ãƒ€ãƒ¼': 'âœ¨', 'ç¥ãƒãƒ¼ãƒ³': 'ğŸ’', 'ã‚¢ã‚¤ã‚¹ãƒãƒ¼ãƒ³': 'âš ï¸', 'ã‚·ãƒ£ãƒé›ª/ã‚´ãƒ­ã‚´ãƒ­é›ª': 'ğŸ’§'} 
MODEL_FEATURE_ORDER = [
	'MaxSnowDepth', 'Snowfall', 'AvgWindSpeed', 'Adj_Temp_Min', 
	'Night_Chill_Factor', 'Cumulative_Heat_History', 'Surface_Hardening_Risk', 'Course_Elev'
]

# å¤‰æ•°ã®åˆæœŸåŒ– 
model_loaded = False 
feature_cache_data = None
past_cache_data = None
future_cache_data = None

# --- ã‚³ãƒ¡ãƒ³ãƒˆå®šç¾©é–¢æ•° ---
def get_snow_condition_comment(condition):
	if condition == 'ãƒ‘ã‚¦ãƒ€ãƒ¼':
		return "äºˆæ¸¬ã•ã‚Œã‚‹é›ªé¢çŠ¶æ…‹ã¯ã€ä½å¯†åº¦ã®æ–°é›ªï¼ˆãƒ‘ã‚¦ãƒ€ãƒ¼ï¼‰ã§ã™ã€‚é«˜ã„æµ®åŠ›ãŒå¾—ã‚‰ã‚Œã‚‹ãŸã‚ã€ã‚µãƒ¼ãƒ•ãƒœãƒ¼ãƒ‰ç­‰ã«ã‚ˆã‚‹æ»‘èµ°ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚"
	elif condition == 'ç¥ãƒãƒ¼ãƒ³':
		return "äºˆæ¸¬ã•ã‚Œã‚‹é›ªé¢çŠ¶æ…‹ã¯ã€ç· ã¾ã£ãŸåœ§é›ªãƒãƒ¼ãƒ³ã§ã™ã€‚é›ªé¢ç¡¬åº¦ãŒé«˜ãã€ã‚¨ãƒƒã‚¸ã®é£Ÿã„è¾¼ã¿ãŒå®‰å®šã™ã‚‹ãŸã‚ã€æ”»ã‚ãŸã‚«ãƒ¼ãƒ“ãƒ³ã‚°ã«æœ€é©ãªã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã§ã™ã€‚"
	elif condition == 'ã‚¢ã‚¤ã‚¹ãƒãƒ¼ãƒ³':
		return "äºˆæ¸¬ã•ã‚Œã‚‹é›ªé¢çŠ¶æ…‹ã¯ã€é›ªé¢ãŒæ°·çµã—ã¦ã„ã‚‹ãƒªã‚¹ã‚¯ãŒé«˜ã„ã‚¢ã‚¤ã‚¹ãƒãƒ¼ãƒ³ã§ã™ã€‚ã‚¨ãƒƒã‚¸è§’ãŒä¸ååˆ†ãªå ´åˆã€åˆ¶å¾¡ä¸èƒ½ã«é™¥ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä½é€Ÿã§ã®æ…é‡ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚"
	elif condition == 'ã‚·ãƒ£ãƒé›ª/ã‚´ãƒ­ã‚´ãƒ­é›ª':
		return "äºˆæ¸¬ã•ã‚Œã‚‹é›ªé¢çŠ¶æ…‹ã¯ã€æ°´åˆ†å«æœ‰ç‡ãŒé«˜ã„èè§£é›ªã¾ãŸã¯å†å‡çµã§ç²’ãŒç²—ããªã£ãŸçŠ¶æ…‹ã§ã™ã€‚æ»‘èµ°æŠµæŠ—ãŒå¤§ãã„ãŸã‚ã€ãƒ¯ãƒƒã‚¯ã‚¹ã®é¸æŠï¼ˆä½æ¸©ç”¨ãƒ»æ¹¿é›ªç”¨ï¼‰ã¨ã€é›ªå´©ç­‰ã®ãƒªã‚¹ã‚¯ç®¡ç†ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚"
	else:
		return "ç¾åœ¨ã®é›ªè³ªã¯ä¸æ˜ã§ã™ã€‚ç¾åœ°ã®æƒ…å ±ã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
# --------------------

# --- 1. ãƒ¢ãƒ‡ãƒ«ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ãƒ­ãƒ¼ãƒ‰ ---
try:
	# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®çµ¶å¯¾ãƒ‘ã‚¹ã‚’å–å¾—ã—ã€ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ã™ã‚‹
	base_dir = os.path.dirname(os.path.abspath(__file__))
except NameError:
	base_dir = os.getcwd() 

try:
	# äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
	model = joblib.load(os.path.join(base_dir, MODEL_FILE))
	
	# éå»ãƒ‡ãƒ¼ã‚¿ã¨æœªæ¥ãƒ‡ãƒ¼ã‚¿ã‚’JSONã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ (å­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã«ã—ãªã„)
	try:
		with open(os.path.join(base_dir, PAST_CACHE_FILE), 'r', encoding='utf-8') as f:
			past_cache_data = json.load(f)
		with open(os.path.join(base_dir, FUTURE_CACHE_FILE), 'r', encoding='utf-8') as f:
			future_cache_data = json.load(f)
	except FileNotFoundError as e:
		st.warning(f"æ³¨æ„: ä¾å­˜ãƒ•ã‚¡ã‚¤ãƒ« ({e.filename}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ã«ã¯å½±éŸ¿ã—ã¾ã›ã‚“ãŒã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ç­‰ã¯ä¸å®Œå…¨ã«ãªã‚Šã¾ã™ã€‚")

	# å¿…é ˆ: ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ­ãƒ¼ãƒ‰ 
	with open(os.path.join(base_dir, FEATURE_CACHE_FILE), 'r', encoding='utf-8') as f:
		feature_cache_data = json.load(f)
		
	model_loaded = True

except FileNotFoundError as e:
	st.error(f"ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç‰¹ã« '{MODEL_FILE}' ã¾ãŸã¯ '{FEATURE_CACHE_FILE}' ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ãƒ‘ã‚¹: {e.filename}")
except Exception as e:
	st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ« ({e.__class__.__name__}) ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
	
# --- 2. äºˆæ¸¬å®Ÿè¡Œé–¢æ•° (ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨) ---
def run_model_prediction(feature_data_list, course_elev):
	
	if not feature_data_list:
		return []
	
	predictions = []
	
	# ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’Numpyé…åˆ—ã«å¤‰æ› (XGBoostãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›)
	features_array = np.array([item['Features'] for item in feature_data_list])

	try:
		# ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬ã‚’å®Ÿè¡Œ (ç¢ºç‡ã‚’å‡ºåŠ›) 
		# å‡ºåŠ›ã¯ [ã‚µãƒ³ãƒ—ãƒ«æ•°, ã‚¯ãƒ©ã‚¹æ•°(4)] ã®ç¢ºç‡é…åˆ—
		probabilities = model.predict_proba(features_array)
	except Exception as e:
		st.error(f"ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
		return []

	for item, probs in zip(feature_data_list, probabilities):
		
		# æœ€ã‚‚ç¢ºç‡ã®é«˜ã„æ¡ä»¶ã‚’æ±ºå®š
		predicted_class = np.argmax(probs)
		top_condition = CONDITIONS.get(predicted_class, 'ä¸æ˜')
		
		predictions.append({
			'Date': item['Date'],
			'Condition': top_condition,
			'Probabilities': probs.tolist(), 
			'Course_Elev': course_elev
		})
			
	return predictions

# --- 3. Streamlit UI (ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒãƒ³) ---

st.set_page_config(layout="wide")

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ¦‚è¦ã¨ã‚¿ã‚¤ãƒˆãƒ«
st.markdown("<h1 style='text-align: center;'>GELACON ã‚²ãƒ¬ãƒ³ãƒ‡ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ </h1>", unsafe_allow_html=True)
st.markdown(
    """
    <p style='text-align: center; color: #777; font-size: 1.1em;'>
    æ°—è±¡æƒ…å ±ã‚’ã‚‚ã¨ã«ã€ã‚²ãƒ¬ãƒ³ãƒ‡ã®æ¨™é«˜ã”ã¨ã®ãƒãƒ¼ãƒ³çŠ¶æ…‹ã‚’äºˆæ¸¬ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã¨ãªã£ã¦ãŠã‚Šã¾ã™ã€‚<br>
    ã“ã‚Œã¯ã‚ãã¾ã§äºˆæ¸¬ãªã®ã§ã€å®Ÿéš›ã®ãƒãƒ¼ãƒ³çŠ¶æ³ã¨ã¯ç•°ãªã‚‹å¯èƒ½æ€§ãŒã”ã–ã„ã¾ã™ã€‚
    </p>
    """,
    unsafe_allow_html=True
)

st.markdown(" AIã«ã‚ˆã‚‹5æ—¥é–“å…ˆã®ãƒãƒ¼ãƒ³äºˆæ¸¬")


if model_loaded and feature_cache_data:
	
	# ãƒªã‚¾ãƒ¼ãƒˆã®é¸æŠ (ã‚µã‚¤ãƒ‰ãƒãƒ¼)
	st.sidebar.header("ğŸ”ï¸ ãƒªã‚¾ãƒ¼ãƒˆé¸æŠ")
	resort_options = ['ç¥ç«‹ã‚¹ãƒãƒ¼ãƒªã‚¾ãƒ¼ãƒˆ', 'ä¸¸æ²¼é«˜åŸã‚¹ã‚­ãƒ¼å ´']
	selected_resort = st.sidebar.selectbox("äºˆæ¸¬ãƒªã‚¾ãƒ¼ãƒˆã‚’é¸æŠ", resort_options)
	st.sidebar.markdown("---")

	# A. é¸æŠãƒªã‚¾ãƒ¼ãƒˆã®è¨­å®šã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
	base_key = 'Kandatsu' if selected_resort == 'ç¥ç«‹ã‚¹ãƒãƒ¼ãƒªã‚¾ãƒ¼ãƒˆ' else 'Marunuma'
	
	# äºˆæ¸¬çµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã¨DataFrame
	all_predictions_df = []
	
	st.header(f"äºˆæ¸¬å¯¾è±¡: {selected_resort}")
	st.markdown("---")
	
	# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ¨™é«˜ãƒªã‚¹ãƒˆã‚’å–å¾—
	target_elevations = COURSE_TARGETS[base_key]
	
	# B. ã‚³ãƒ¼ã‚¹ã”ã¨ã®äºˆæ¸¬å®Ÿè¡Œãƒ«ãƒ¼ãƒ—
	for course_elev in target_elevations:
		
		# ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ã‚­ãƒ¼ã‚’ä½œæˆ
		feature_key = f"{base_key}_{course_elev}m"
		
		# è©²å½“ã™ã‚‹ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚’å–å¾—
		feature_data_list = feature_cache_data['features'].get(feature_key, [])
		
		if not feature_data_list:
			st.warning(f"æ³¨æ„: {feature_key} ã®ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
			continue # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
		
		# 1. äºˆæ¸¬ã®å®Ÿè¡Œ (æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—)
		predictions = run_model_prediction(feature_data_list, course_elev)
		
		# äºˆæ¸¬çµæœã‚’DataFrameã«å¤‰æ›ã—ã¦çµ±åˆ
		df_course = pd.DataFrame(predictions)
		df_course['Course_Elev'] = df_course['Course_Elev'].astype(str) + 'm'
		all_predictions_df.append(df_course)

	# äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿UIã‚’è¡¨ç¤º
	if all_predictions_df:
		df_combined = pd.concat(all_predictions_df)
		
		# --- UIè¡¨ç¤ºã®ãƒ¡ã‚¤ãƒ³éƒ¨åˆ† ---
		
		# 1. æ¨™é«˜ã”ã¨ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚µãƒãƒªï¼ˆå·¦ä¸Šï¼‰
		st.subheader("1. ğŸ—ºï¸ ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ãƒãƒƒãƒ—")
		
		# å„æ—¥ä»˜ã§æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ã‚’å–å¾—
		df_combined['Top_Condition'] = df_combined.apply(lambda row: CONDITIONS[np.argmax(row['Probabilities'])], axis=1)
		
		# ä¿®æ­£: çµµæ–‡å­—ã¨æ—¥æœ¬èªåã‚’çµåˆã—ãŸæ–°ã—ã„ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
		def format_condition(row):
			emoji = CONDITION_EMOJIS[row['Top_Condition']]
			# ç•¥ç§°ã‚’ä½¿ç”¨ã›ãšã€å®Œå…¨ãªåç§°ã‚’ä½¿ç”¨
			name = row['Top_Condition'] 
			return f"{emoji} {name}"
			
		df_combined['Formatted_Condition'] = df_combined.apply(format_condition, axis=1)
		
		# Plotly Heatmap (imshow) ã®ä»£ã‚ã‚Šã«Pandas Stylerã‚’ä½¿ç”¨
		# æ¨™é«˜(index)ã¨æ—¥ä»˜(columns)ã§ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
		pivot_table_formatted = df_combined.pivot_table(
			index='Course_Elev', 
			columns='Date', 
			values='Formatted_Condition', # çµåˆã—ãŸæ–‡å­—åˆ—ã‚’ä½¿ç”¨
			aggfunc='first'
		# ä¿®æ­£å¾Œã®ãƒã‚¤ãƒ³ãƒˆ: target_elevations ã‚’ãã®ã¾ã¾ä½¿ç”¨ (é™é †ã§ã‚ã‚‹ãŸã‚)
		).reindex([str(e) + 'm' for e in target_elevations])
		
		# æ¨™é«˜ã®æ•°å€¤ã ã‘ã‚’å–ã‚Šå‡ºã—ã€ã‚½ãƒ¼ãƒˆã—ã¦ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®åŸºæº–ã‚’ä½œæˆ
		elev_floats = [float(e.replace('m', '')) for e in pivot_table_formatted.index]
		min_elev = min(elev_floats)
		max_elev = max(elev_floats)
		
		# --- ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•° ---
		def elevation_gradient(s):
			# å„æ¨™é«˜è¡Œã«å¯¾å¿œã™ã‚‹ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨ã™ã‚‹
			styles = []
			elev_str = s.name
			elev_val = float(elev_str.replace('m', ''))
			
			# 0.1ã‹ã‚‰0.7ã®ç¯„å›²ã§é’ã®æ¿ƒæ·¡ã‚’è¨ˆç®—
			normalized_elev = (elev_val - min_elev) / (max_elev - min_elev) if max_elev > min_elev else 0.5
			# Hue=240(é’), Saturation=70%, Lightness=70% - (normalized)*30% (æ¨™é«˜ãŒé«˜ã„ã»ã©è‰²ãŒæ¿ƒã„é’)
			lightness = 70 - (normalized_elev * 30) 
			
			bg_color = f"hsl(240, 70%, {lightness}%)"
			
			
			for _ in s.index:
				styles.append(f'background-color: {bg_color}; color: white; text-align: center; font-size: 0.75em;')
			return styles
		# ------------------------------------

		# Stylerã‚’é©ç”¨ã—ã¦HTMLãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã—ã¦Streamlitã«è¡¨ç¤º
		st.dataframe(
			pivot_table_formatted.style.apply(elevation_gradient, axis=1), 
			use_container_width=True,
			height=len(target_elevations) * 70
		)
		
		st.markdown("---")
		
		# 2. ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³é¸æŠã«ã‚ˆã‚‹è©³ç´°ç¢ºç‡ã‚°ãƒ©ãƒ•ã¨ã‚³ãƒ¡ãƒ³ãƒˆ
		st.subheader("2. ğŸ“Š è©³ç´°äºˆæ¸¬ç¢ºç‡ã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
		
		col1, col2 = st.columns(2)
		
		unique_dates = df_combined['Date'].unique()
		unique_elevs = df_combined['Course_Elev'].unique()

		with col1:
			selected_date = st.selectbox("äºˆæ¸¬æ—¥ã‚’é¸æŠ", unique_dates)
			
		with col2:
			selected_elev = st.selectbox("ã‚³ãƒ¼ã‚¹æ¨™é«˜ã‚’é¸æŠ (m)", unique_elevs)
			
		df_filtered = df_combined[
			(df_combined['Date'] == selected_date) & 
			(df_combined['Course_Elev'] == selected_elev)
		].iloc[0]
		

		st.markdown("<br><br>", unsafe_allow_html=True) 
		
		st.markdown("#### ğŸ’¬ ä»Šæ—¥ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
		top_condition_for_comment = df_filtered['Top_Condition']
		st.info(get_snow_condition_comment(top_condition_for_comment))
		
		st.markdown("<br><br>", unsafe_allow_html=True) 
		
		prob_data = pd.DataFrame({
			'Condition': list(CONDITIONS.values()),
			'Probability': df_filtered['Probabilities']
		})
		
		prob_data['Probability'] = (prob_data['Probability'] * 100).round(1)
		prob_data = prob_data.sort_values(by='Probability', ascending=False)

		# å††ã‚°ãƒ©ãƒ•ã®æç”»
		prob_fig = px.pie(
			prob_data, 
			values='Probability', 
			names='Condition', 
			title=f"{selected_elev} / {selected_date} ã®ãƒãƒ¼ãƒ³ç¢ºç‡",
			color='Condition',
			color_discrete_map={
				'ãƒ‘ã‚¦ãƒ€ãƒ¼': 'lightblue', 
				'ç¥ãƒãƒ¼ãƒ³': 'green', 
				'ã‚¢ã‚¤ã‚¹ãƒãƒ¼ãƒ³': 'red', 
				'ã‚·ãƒ£ãƒé›ª/ã‚´ãƒ­ã‚´ãƒ­é›ª': 'orange'
			}
		)
		prob_fig.update_traces(textinfo='percent+label')
		st.plotly_chart(prob_fig, use_container_width=True)

	else:
		st.warning("é¸æŠã—ãŸãƒªã‚¾ãƒ¼ãƒˆã€ã¾ãŸã¯ã‚³ãƒ¼ã‚¹ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

else:
	st.error("äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚’èµ·å‹•ã§ãã¾ã›ã‚“ã€‚å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒæƒã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# --- å®Ÿè¡Œ ---
if __name__ == '__main__':
	pass